
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>OctaveQUEFFELEC_tp2</title><meta name="generator" content="MATLAB 8.6"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-10-04"><meta name="DC.source" content="OctaveQUEFFELEC_tp2.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">TP2 Minimisation de la fonction log barriere</a></li><li><a href="#3">Calcul de alpha en utilisant la fonction backslash</a></li><li><a href="#4">test avec CVX</a></li><li><a href="#5">Calcul du gradient en derivant la fonction de cout</a></li><li><a href="#6">test de gradlogB par approximation du gradient par differences finis</a></li><li><a href="#7">Calcul de la matrice Hessienne</a></li><li><a href="#8">Methode de gradient a pas fixe</a></li><li><a href="#9">Methode de gradient a pas variable</a></li><li><a href="#10">Methode de gradient a pas optimal</a></li><li><a href="#11">Methode de newton regularise</a></li><li><a href="#12">Conclusion</a></li></ul></div><pre class="codeinput">close <span class="string">all</span>
clear <span class="string">all</span>
clc
</pre><h2>TP2 Minimisation de la fonction log barriere<a name="2"></a></h2><p>test de la fonction CoutLogB alpha un polynome log(1-eps)~eps</p><pre class="codeinput">n=100;
x=sort(rand(n,1));
f=cos(pi*x);
sig=0.1;
y=f+sig*randn(size(f));

X=[ones(size(x)) x x.^2 x.^3 x.^4 x.^5 x.^6 x.^7 x.^8 x.^9 x.^10 x.^11 x.^12];
</pre><h2>Calcul de alpha en utilisant la fonction backslash<a name="3"></a></h2><pre class="codeinput">c=1.5;
alpha=X\y;
coutmmc=(X*alpha-y)'*(X*alpha-y)/c;
cout = CoutLogB(alpha,X,y,c);
gradBS=grad_logB(alpha,X,y,c);


<span class="comment">% Quand C est tres grand, on retrouve bien les moindres carrees</span>
</pre><h2>test avec CVX<a name="4"></a></h2><pre class="codeinput">c=1.55;
tic
cvx_begin
    variables <span class="string">ac(size(X,2),1)</span>
    minimize( -sum(log(1-(X*ac - y).^2/c^2)))

cvx_end
tCVX=toc
coutCVX = CoutLogB(ac,X,y,c);
gradCVX=grad_logB(ac,X,y,c);

<span class="comment">% On trouve un cout faible de 0.47 avec CVX, et de 0.51 avec la fonction backslash, pour un c=1.55</span>
</pre><pre class="codeoutput">CVX Warning:
   Models involving "log" or other functions in the log, exp, and entropy
   family are solved using an experimental successive approximation method.
   This method is slower and less reliable than the method CVX employs for
   other models. Please see the section of the user's guide entitled
       &lt;a href="file:////home/oqueffelec/bureau/cvx/doc/advanced.html#the-successive-approximation-method"&gt;The successive approximation method&lt;/a&gt;
   for more details about the approach, and for instructions on how to
   suppress this warning message in the future.
 
Successive approximation method to be employed.
   For improved efficiency, SDPT3 is solving the dual problem.
   SDPT3 will be called several times to refine the solution.
   Original size: 600 variables, 213 equality constraints
   100 exponentials add 800 variables, 500 equality constraints
-----------------------------------------------------------------
 Cones  |             Errors              |
Mov/Act | Centering  Exp cone   Poly cone | Status
--------+---------------------------------+---------
100/100 | 1.197e+00  9.103e-02  0.000e+00 | Solved
100/100 | 1.895e-01  2.415e-03  0.000e+00 | Solved
100/100 | 1.921e-02  2.458e-05  1.277e-11 | Solved
100/100 | 2.448e-03  3.991e-07  0.000e+00 | Solved
 79/ 98 | 1.199e-02  9.568e-06  8.334e-11 | Solved
 19/100 | 1.726e-03  1.986e-07  1.704e-10 | Solved
 73/ 99 | 9.797e-03  6.404e-06  0.000e+00 | Solved
  1/ 75 | 7.015e-04  3.268e-08  0.000e+00 | Solved
  1/ 63 | 6.378e-04  2.693e-08  0.000e+00 | Solved
  4/ 79 | 1.006e-03  6.741e-08  0.000e+00 | Solved
  7/ 88 | 1.392e-03  1.292e-07  0.000e+00 | Solved
  8/ 93 | 1.294e-03  1.117e-07  0.000e+00 | Solved
 67/ 92 | 1.038e-02  7.180e-06  0.000e+00 | Inaccurate/Solved
 77/ 98 | 8.249e-03  4.540e-06  0.000e+00 | Solved
 79/ 93 | 7.802e-03  4.056e-06  0.000e+00 | Solved
 70/ 96 | 1.065e-02  7.574e-06  0.000e+00 | Solved
  9/ 80 | 1.692e-03  1.910e-07  0.000e+00 | Solved
 15/ 85 | 1.299e-03  1.124e-07  0.000e+00 | Solved
  9/ 85 | 9.249e-04  5.678e-08  4.934e-11 | Solved
  0/ 37 | 2.579e-04  4.376e-09  1.067e-11 | Solved
-----------------------------------------------------------------
Status: Solved
Optimal value (cvx_optval): +0.315683
 

tCVX =

   33.9789

</pre><h2>Calcul du gradient en derivant la fonction de cout<a name="5"></a></h2><pre class="codeinput">g = grad_logB(alpha,X,y,c);
</pre><h2>test de gradlogB par approximation du gradient par differences finis<a name="6"></a></h2><pre class="codeinput">a =zeros(size(X,2),1);
err = X*a-y;
c =max(abs(err))+.01;
fc = CoutLogB(a,X,y,c);
grad = grad_logB(a,X,y,c);

[n,p] =size(X);
chouia =sqrt(eps);
<span class="keyword">for</span> i=1:p
    d =zeros(p,1);
    d(i) = 1;
    fd = CoutLogB(a+chouia*d,X,y,c);
    e(i) = (grad(i) + ((fc - fd)/chouia))/grad(i);
<span class="keyword">end</span>
</pre><h2>Calcul de la matrice Hessienne<a name="7"></a></h2><pre class="codeinput">H = Hess_logB(a,X,y,c);
</pre><h2>Methode de gradient a pas fixe<a name="8"></a></h2><pre class="codeinput">a=a*0;
nt=1000;
xt=linspace(0,1,nt)';
Xt=[ones(size(xt)) xt xt.^2 xt.^3 xt.^4 xt.^5 xt.^6 xt.^7 xt.^8 xt.^9 xt.^10 xt.^11 xt.^12];
<span class="comment">% Choix du pas en utilisant la vp max de la hessien calcul&eacute; precedemment</span>
vp_H=eig(H);
pas=1/vp_H(1);
g = 1;
k = 1;
nbitemax = 10000;
fprintf(1,<span class="string">'--------------------------\n'</span>);
fprintf(1,<span class="string">'nb ite cout \n'</span>);
fprintf(1,<span class="string">'--------------------------\n'</span>);
figure(1);
hold <span class="string">on</span>
tic;
<span class="keyword">while</span>((norm(g) &gt; 0.005) &amp;&amp; (k &lt; nbitemax))
    cout_pasfix = CoutLogB(a,X,y,c);
<span class="comment">%     fprintf(1,'%8d %12.4f \n',k, cout);</span>
    g = grad_logB(a,X,y,c);
    a = a - pas*g;
    <span class="keyword">if</span> mod(k,100) == 0 ,
       h1= plot(xt,Xt*a,<span class="string">'--r'</span>);
    <span class="keyword">end</span>;
    k = k+1;
<span class="keyword">end</span>
tPasFix=toc;
h2=plot(xt,Xt*a,<span class="string">'b'</span>,<span class="string">'LineWidth'</span>,2);
h3=plot(x,y,<span class="string">'or'</span>);
title(<span class="string">'Methode du gradient a pas fixe'</span>);
legend([h1 h3], <span class="string">'polynome calcul&eacute;'</span>,<span class="string">'donnees'</span>);
hold <span class="string">off</span>

<span class="comment">% Le temps de calcul est plus rapide pour le pas fixe que pour CVX</span>
<span class="comment">% Si le pas choisi est trop grand on risque de diverger, si</span>
<span class="comment">% il est trop petit, la fonction convergera trop lentement</span>

<span class="comment">% temps d'execution du pas fixe avec un pas=1/L ou L=sup lambda de la</span>
<span class="comment">% hessien : 0.34s pour un cout de 1.01</span>
</pre><pre class="codeoutput">--------------------------
nb ite cout 
--------------------------
</pre><img vspace="5" hspace="5" src="OctaveQUEFFELEC_tp2_01.png" alt=""> <h2>Methode de gradient a pas variable<a name="9"></a></h2><pre class="codeinput">a=a*0;
g=1;
k=1;
alpha=0.15;
beta=2;
tol=0.005;
cout_old=0;
figure(2);
hold <span class="string">on</span>
tic;
<span class="keyword">while</span>((norm(g) &gt; tol) &amp;&amp; (k &lt; nbitemax))
    cout_pasvar = CoutLogB(a,X,y,c);
<span class="comment">%     fprintf(1,'%8d %12.5f %12.8f \n',k, cout, pas);</span>
    <span class="keyword">if</span>(cout_pasvar &lt; cout_old)
        pas = (1+alpha)*pas;
        cout_old = cout_pasvar;
    <span class="keyword">else</span>
        a = a + pas*g;
        pas = pas/beta;
    <span class="keyword">end</span>
    g = grad_logB(a,X,y,c);
    a = a - pas*g;
    <span class="keyword">if</span> mod(k,10) == 0 ,
        plot(xt,Xt*a,<span class="string">'--r'</span>);
    <span class="keyword">end</span>;
    k = k+1;
<span class="keyword">end</span>
tPasVar=toc;
plot(xt,Xt*a,<span class="string">'b'</span>,<span class="string">'LineWidth'</span>,2);
plot(x,y,<span class="string">'or'</span>);
title(<span class="string">'Methode du gradient a pas variable'</span>);
legend(<span class="string">'polynome calcul&eacute;'</span>,<span class="string">'donnees'</span>);
hold <span class="string">off</span>
<span class="comment">% temps d'execution du pas variable avec alpha=0.15: 1.17s pour un cout de</span>
<span class="comment">% 1.01</span>
</pre><img vspace="5" hspace="5" src="OctaveQUEFFELEC_tp2_02.png" alt=""> <h2>Methode de gradient a pas optimal<a name="10"></a></h2><pre class="codeinput">a =zeros(size(X,2),1);
pas=0.001;
g = 1;
k = 1;
nbitemax = 10000;
figure(3);
hold <span class="string">on</span>
tic;
<span class="keyword">while</span>((norm(g) &gt; 0.005) &amp;&amp; (k &lt; nbitemax))
    cout_pasopt = CoutLogB(a,X,y,c);
    g = grad_logB(a,X,y,c);
    H = Hess_logB(a,X,y,c);
    pas = (g'*g)/(g'*H*g);
    a = a - pas*g;
    <span class="keyword">if</span> mod(k,100) == 0 ,
        plot(xt,Xt*a,<span class="string">'--r'</span>);
    <span class="keyword">end</span>;
    k = k+1;
<span class="keyword">end</span>
tPasOpt=toc;
plot(xt,Xt*a,<span class="string">'b'</span>,<span class="string">'LineWidth'</span>,2);
plot(x,y,<span class="string">'or'</span>);
title(<span class="string">'Methode de gradient a pas optimal'</span>);
legend( <span class="string">'polynome calcul&eacute;'</span>,<span class="string">'donnees'</span>);
hold <span class="string">off</span>
<span class="comment">% temps d'execution du pas optimal avec un pas initial de 0.001: 0.63s pour</span>
<span class="comment">% un cout de 0.8</span>
</pre><img vspace="5" hspace="5" src="OctaveQUEFFELEC_tp2_03.png" alt=""> <h2>Methode de newton regularise<a name="11"></a></h2><p>Avec lambda=0</p><pre class="codeinput">a=a*0;
err=0.005;
g=1;
k=1;
lambda=0;
I =eye(p);
figure(4)
hold <span class="string">on</span>
tic;
<span class="keyword">while</span>((norm(g) &gt; err) &amp; (k &lt; nbitemax))
    cout_newt = CoutLogB(a,X,y,c);
<span class="comment">%     fprintf(1,'%8d %12.4f \n',k, cout_newt);</span>
    g = grad_logB(a,X,y,c);
    H = Hess_logB(a,X,y,c);
    dir= (H+lambda*I)\g;
    a = a -dir;
<span class="comment">%     if mod(k,10) == 0 ,</span>
        plot(xt,Xt*a,<span class="string">'--r'</span>);
<span class="comment">%     end;</span>
k = k+1;
<span class="keyword">end</span>
tNewton=toc;
plot(xt,Xt*a,<span class="string">'b'</span>,<span class="string">'LineWidth'</span>,2);
plot(x,y,<span class="string">'or'</span>);
title(<span class="string">'Methode de newton regularise avec lambda=0'</span>);
legend(<span class="string">'polynome calcul&eacute;'</span>,<span class="string">'donnees'</span>);
hold <span class="string">off</span>

<span class="comment">% temps d'execution du pas optimal: 0.001s avec lambda nul,</span>
<span class="comment">% pour un cout de 0.71</span>

<span class="comment">% % Avec lambda&gt;0</span>
a=a*0;
err=0.005;
g=1;
k=1;
lambda =sqrt(eps);
I =eye(p);
figure(5)
hold <span class="string">on</span>
tic;
<span class="keyword">while</span>((norm(g) &gt; err) &amp; (k &lt; nbitemax))
    cout_newt = CoutLogB(a,X,y,c);
<span class="comment">%     fprintf(1,'%8d %12.4f \n',k, cout_newt);</span>
    g = grad_logB(a,X,y,c);
    H = Hess_logB(a,X,y,c);
    dir= (H+lambda*I)\g;
    a = a -dir;
<span class="comment">%     if mod(k,10) == 0 ,</span>
        plot(xt,Xt*a,<span class="string">'--r'</span>);
<span class="comment">%     end;</span>
k = k+1;
<span class="keyword">end</span>
tNewton=toc;
plot(xt,Xt*a,<span class="string">'b'</span>,<span class="string">'LineWidth'</span>,2);
plot(x,y,<span class="string">'or'</span>);
title(<span class="string">'Methode de newton regularise avec lambda&gt;0'</span>);
legend(<span class="string">'polynome calcul&eacute;'</span>,<span class="string">'donnees'</span>);
hold <span class="string">off</span>

<span class="comment">% temps d'execution du pas optimal: 0.002s avec lambda tres proche de zero,</span>
<span class="comment">% pour un cout de 0.71</span>
<span class="comment">% Si l'on ne regularise pas, un risque un probleme de surapprentissage</span>
</pre><img vspace="5" hspace="5" src="OctaveQUEFFELEC_tp2_04.png" alt=""> <img vspace="5" hspace="5" src="OctaveQUEFFELEC_tp2_05.png" alt=""> <h2>Conclusion<a name="12"></a></h2><p>Pour resoudre notre probleme d'optimisation, la methode regularisee de Newton semble etre la plus performante en terme de cout minimale, de temps d'execution et de nombre d'iterations. CVX donne un cout encore plus faible mais le temps dexecution est bcp trop long (~45sec).La methode du pas optimal est un peu moins performante, mais le cout optenu et son temps dexecution reste correcte. Par contre, les methodes du pas fixe et du pas variable sont loin d'etre aussi efficace que les 2 premieres, que se soit en terme de temps de calcul ou de resultat.</p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015b</a><br></p></div><!--
##### SOURCE BEGIN #####
close all
clear all
clc
%% TP2 Minimisation de la fonction log barriere
% test de la fonction CoutLogB
% alpha un polynome
% log(1-eps)~eps

n=100;
x=sort(rand(n,1));
f=cos(pi*x);
sig=0.1;
y=f+sig*randn(size(f));

X=[ones(size(x)) x x.^2 x.^3 x.^4 x.^5 x.^6 x.^7 x.^8 x.^9 x.^10 x.^11 x.^12];

%% Calcul de alpha en utilisant la fonction backslash

c=1.5;
alpha=X\y;
coutmmc=(X*alpha-y)'*(X*alpha-y)/c;
cout = CoutLogB(alpha,X,y,c);
gradBS=grad_logB(alpha,X,y,c);


% Quand C est tres grand, on retrouve bien les moindres carrees

%% test avec CVX
c=1.55;
tic 
cvx_begin
    variables ac(size(X,2),1)
    minimize( -sum(log(1-(X*ac - y).^2/c^2)))
    
cvx_end
tCVX=toc
coutCVX = CoutLogB(ac,X,y,c);
gradCVX=grad_logB(ac,X,y,c);

% On trouve un cout faible de 0.47 avec CVX, et de 0.51 avec la fonction backslash, pour un c=1.55

%% Calcul du gradient en derivant la fonction de cout 

g = grad_logB(alpha,X,y,c);

%% test de gradlogB par approximation du gradient par differences finis

a =zeros(size(X,2),1);
err = X*a-y;
c =max(abs(err))+.01;
fc = CoutLogB(a,X,y,c);
grad = grad_logB(a,X,y,c);

[n,p] =size(X);
chouia =sqrt(eps);
for i=1:p 
    d =zeros(p,1);
    d(i) = 1;
    fd = CoutLogB(a+chouia*d,X,y,c);
    e(i) = (grad(i) + ((fc - fd)/chouia))/grad(i);
end

%% Calcul de la matrice Hessienne 

H = Hess_logB(a,X,y,c);

%% Methode de gradient a pas fixe 
a=a*0;
nt=1000;
xt=linspace(0,1,nt)';
Xt=[ones(size(xt)) xt xt.^2 xt.^3 xt.^4 xt.^5 xt.^6 xt.^7 xt.^8 xt.^9 xt.^10 xt.^11 xt.^12];
% Choix du pas en utilisant la vp max de la hessien calculé precedemment
vp_H=eig(H);
pas=1/vp_H(1);
g = 1;
k = 1;
nbitemax = 10000;
fprintf(1,'REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH\n');
fprintf(1,'nb ite cout \n');
fprintf(1,'REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH\n');
figure(1);
hold on 
tic;
while((norm(g) > 0.005) && (k < nbitemax))
    cout_pasfix = CoutLogB(a,X,y,c);
%     fprintf(1,'%8d %12.4f \n',k, cout);
    g = grad_logB(a,X,y,c);
    a = a - pas*g;
    if mod(k,100) == 0 ,
       h1= plot(xt,Xt*a,'REPLACE_WITH_DASH_DASHr');
    end;
    k = k+1;
end
tPasFix=toc;
h2=plot(xt,Xt*a,'b','LineWidth',2);
h3=plot(x,y,'or');
title('Methode du gradient a pas fixe');
legend([h1 h3], 'polynome calculé','donnees');
hold off

% Le temps de calcul est plus rapide pour le pas fixe que pour CVX
% Si le pas choisi est trop grand on risque de diverger, si
% il est trop petit, la fonction convergera trop lentement 

% temps d'execution du pas fixe avec un pas=1/L ou L=sup lambda de la
% hessien : 0.34s pour un cout de 1.01
%% Methode de gradient a pas variable 
a=a*0;
g=1;
k=1;
alpha=0.15;
beta=2;
tol=0.005;
cout_old=0;
figure(2);
hold on 
tic;
while((norm(g) > tol) && (k < nbitemax))
    cout_pasvar = CoutLogB(a,X,y,c);
%     fprintf(1,'%8d %12.5f %12.8f \n',k, cout, pas);
    if(cout_pasvar < cout_old)
        pas = (1+alpha)*pas;
        cout_old = cout_pasvar;
    else
        a = a + pas*g;
        pas = pas/beta;
    end
    g = grad_logB(a,X,y,c);
    a = a - pas*g;
    if mod(k,10) == 0 ,
        plot(xt,Xt*a,'REPLACE_WITH_DASH_DASHr');
    end;
    k = k+1;
end
tPasVar=toc;
plot(xt,Xt*a,'b','LineWidth',2);
plot(x,y,'or');
title('Methode du gradient a pas variable');
legend('polynome calculé','donnees');
hold off
% temps d'execution du pas variable avec alpha=0.15: 1.17s pour un cout de
% 1.01

%% Methode de gradient a pas optimal

a =zeros(size(X,2),1);
pas=0.001;
g = 1;
k = 1;
nbitemax = 10000;
figure(3);
hold on 
tic;
while((norm(g) > 0.005) && (k < nbitemax))
    cout_pasopt = CoutLogB(a,X,y,c);
    g = grad_logB(a,X,y,c);
    H = Hess_logB(a,X,y,c);
    pas = (g'*g)/(g'*H*g);
    a = a - pas*g;
    if mod(k,100) == 0 ,
        plot(xt,Xt*a,'REPLACE_WITH_DASH_DASHr');
    end;
    k = k+1;
end
tPasOpt=toc;
plot(xt,Xt*a,'b','LineWidth',2);
plot(x,y,'or');
title('Methode de gradient a pas optimal');
legend( 'polynome calculé','donnees');
hold off
% temps d'execution du pas optimal avec un pas initial de 0.001: 0.63s pour
% un cout de 0.8
%% Methode de newton regularise
% Avec lambda=0
a=a*0;
err=0.005;
g=1;
k=1;
lambda=0;
I =eye(p);
figure(4)
hold on
tic;
while((norm(g) > err) & (k < nbitemax))
    cout_newt = CoutLogB(a,X,y,c);
%     fprintf(1,'%8d %12.4f \n',k, cout_newt);
    g = grad_logB(a,X,y,c);
    H = Hess_logB(a,X,y,c);
    dir= (H+lambda*I)\g;
    a = a -dir;
%     if mod(k,10) == 0 ,
        plot(xt,Xt*a,'REPLACE_WITH_DASH_DASHr');
%     end;
k = k+1;
end
tNewton=toc;
plot(xt,Xt*a,'b','LineWidth',2);
plot(x,y,'or');
title('Methode de newton regularise avec lambda=0');
legend('polynome calculé','donnees');
hold off

% temps d'execution du pas optimal: 0.001s avec lambda nul,
% pour un cout de 0.71

% % Avec lambda>0
a=a*0;
err=0.005;
g=1;
k=1;
lambda =sqrt(eps);
I =eye(p);
figure(5)
hold on
tic;
while((norm(g) > err) & (k < nbitemax))
    cout_newt = CoutLogB(a,X,y,c);
%     fprintf(1,'%8d %12.4f \n',k, cout_newt);
    g = grad_logB(a,X,y,c);
    H = Hess_logB(a,X,y,c);
    dir= (H+lambda*I)\g;
    a = a -dir;
%     if mod(k,10) == 0 ,
        plot(xt,Xt*a,'REPLACE_WITH_DASH_DASHr');
%     end;
k = k+1;
end
tNewton=toc;
plot(xt,Xt*a,'b','LineWidth',2);
plot(x,y,'or');
title('Methode de newton regularise avec lambda>0');
legend('polynome calculé','donnees');
hold off

% temps d'execution du pas optimal: 0.002s avec lambda tres proche de zero,
% pour un cout de 0.71
% Si l'on ne regularise pas, un risque un probleme de surapprentissage 

%% Conclusion 
% Pour resoudre notre probleme d'optimisation, la methode regularisee de
% Newton semble etre la plus performante en terme de cout minimale, de
% temps d'execution et de nombre d'iterations. CVX donne un cout encore plus faible mais le temps dexecution est bcp trop long (~45sec).La methode du pas optimal
% est un peu moins performante, mais le cout optenu et son temps dexecution
% reste correcte. Par contre, les methodes du pas fixe et du pas variable
% sont loin d'etre aussi efficace que les 2 premieres, que se soit en terme
% de temps de calcul ou de resultat.





    
##### SOURCE END #####
--></body></html>